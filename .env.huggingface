# ============================================
# HUGGINGFACE SPACES CONFIGURATION (FREE TIER)
# ============================================

# Environment Detection
IS_HUGGINGFACE_SPACE=true
DEPLOYMENT_ENV=huggingface

# ============================================
# LLM PROVIDER CONFIGURATION
# ============================================

# Provider Priority (explicit for HF Spaces)
LLM_PROVIDER_PRIORITY=llama_cpp,openai,anthropic,hf_inference
LLM_DEFAULT_PROVIDER=llama_cpp

# Provider Availability
ENABLE_OLLAMA=false          # Ollama not available on HF Spaces
ENABLE_LLAMA_CPP=true        # Primary: llama.cpp with GGUF models
ENABLE_OPENAI=false          # Disabled unless you add API key
ENABLE_ANTHROPIC=false       # Disabled unless you add API key
ENABLE_HF_INFERENCE=false    # Disabled unless you enable below

# ============================================
# LLAMA.CPP CONFIGURATION (PRIMARY PROVIDER)
# ============================================

# Model Selection (Hermes-2-Pro-Llama-3-8B is excellent for legal analysis)
LLAMA_CPP_MODEL_REPO=NousResearch/Hermes-2-Pro-Llama-3-8B-GGUF
LLAMA_CPP_MODEL_FILE=Hermes-2-Pro-Llama-3-8B-GGUF.Q4_K_M.gguf

# CPU-Only Configuration (CRITICAL for free tier)
LLAMA_CPP_N_GPU_LAYERS=0      # 0 = CPU only
LLAMA_CPP_N_CTX=4096          # Context window
LLAMA_CPP_N_BATCH=128         # Smaller batches for CPU memory
LLAMA_CPP_N_THREADS=4         # CPU threads (optimize for free tier)

# ============================================
# LLM GENERATION SETTINGS
# ============================================

# Generation Parameters
LLM_TEMPERATURE=0.1           # Low temperature for consistent legal analysis
LLM_MAX_TOKENS=1024           # Max tokens per response
LLM_TOP_P=0.95                # Top-p sampling
LLM_REPEAT_PENALTY=1.1        # Repeat penalty

# System Prompt (optimized for legal analysis)
LLM_SYSTEM_PROMPT="You are a specialized legal contract analyst. Provide concise, accurate analysis focusing on risk identification, clause interpretation, and practical recommendations."

# ============================================
# EXTERNAL API FALLBACKS (OPTIONAL)
# ============================================

# OpenAI API (optional fallback - add your key in Space Secrets)
# ENABLE_OPENAI=true
# OPENAI_API_KEY=sk-xxxxxxx
# OPENAI_MODEL=gpt-3.5-turbo
# OPENAI_TIMEOUT=30
# OPENAI_MAX_TOKENS=1024

# Anthropic API (optional fallback)
# ENABLE_ANTHROPIC=true
# ANTHROPIC_API_KEY=sk-ant-xxxxxxx
# ANTHROPIC_MODEL=claude-3-haiku-20240307
# ANTHROPIC_TIMEOUT=30

# HuggingFace Inference API (optional - uses HF token from environment)
# ENABLE_HF_INFERENCE=true
# HF_MODEL_ID=meta-llama/Llama-2-7b-chat-hf
# HF_API_TOKEN=${HF_TOKEN}  # Automatically provided by HF Spaces

# ============================================
# APPLICATION SETTINGS
# ============================================

# File Upload Limits
MAX_UPLOAD_SIZE=10485760      # 10MB (free tier memory consideration)
ALLOWED_EXTENSIONS=.pdf,.docx,.txt

# Contract Analysis Limits
MIN_CONTRACT_LENGTH=300       # Minimum characters
MAX_CONTRACT_LENGTH=500000    # Maximum characters (500KB)

# Performance Settings
MODEL_CACHE_SIZE=2            # Cache 2 models in memory (free tier limit)
USE_GPU=false                 # Force CPU-only for free tier

# Logging
LOG_LEVEL=INFO
LOG_FILE=/tmp/app.log         # Use tmp for ephemeral storage

# Cache Settings
ENABLE_CACHE=true
CACHE_TTL=3600                # 1 hour cache
CACHE_DIR=/tmp/cache          # Use tmp for ephemeral storage

# Model Cache Directory (HF Spaces uses /data for persistence)
MODEL_CACHE_DIR=/data/models  # CRITICAL: HF Spaces persists /data

# Rate Limiting (important for free tier)
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=5         # Reduced for free tier
RATE_LIMIT_PERIOD=60          # Per minute

# ============================================
# SERVER CONFIGURATION
# ============================================

# Server Settings (HF Spaces uses port 7860)
HOST=0.0.0.0
PORT=7860                     # HF Spaces default port
WORKERS=1                     # Single worker for free tier
RELOAD=false                  # Disable reload in production

# CORS (configure for your frontend)
CORS_ORIGINS=["https://*.hf.space", "http://localhost:3000"]
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=["*"]
CORS_ALLOW_HEADERS=["*"]

# ============================================
# PDF REPORT SETTINGS
# ============================================

PDF_FONT_SIZE=10
PDF_MARGIN=0.5
PDF_PAGE_SIZE=letter